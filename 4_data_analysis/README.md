# ğŸ§  Lead-Time Prediction â€” Data Analysis & Modeling

PyCaret Regression Pipeline for Generator Manufacturing

This folder contains all scripts, configuration, and output artifacts used to
build machine-learning models that predict the lead time to finish a generator
based on pre-manufacturing information.

This stage ensuring full reproducibility and transparency.

## ğŸ“Œ Overview

We use PyCaret Regression to evaluate multiple ML models, select the top
performers, generate evaluation artifacts, and store everything in a timestamped
"run" folder.

This ensures:

- Full separation of modeling runs

- Perfect reproducibility

- No overwriting previous results

- Easy comparison across versions

The goal: Predict the variable

```nginx
target_lead_time_to_finish_days
```

using only features known before production starts.

## ğŸ”§ Pipeline Flow (Detailed)

```mathematica
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ 1. Load Dataset    â”‚
                         â”‚ from 1_datasets/   â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ 2. Preprocess For Modeling â”‚
                      â”‚  - Drop leakage columns    â”‚
                      â”‚  - Convert order_date      â”‚
                      â”‚  - Keep target variable    â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ 3. PyCaret Setup                       â”‚
                â”‚  - Auto preprocessing                  â”‚
                â”‚  - Train/test split (80/20)            â”‚
                â”‚  - Date feature extraction             â”‚
                â”‚  - Encoding, imputation                â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ 4. compare_models()                          â”‚
           â”‚  - Train many algorithms                     â”‚
           â”‚  - Rank by metrics                           â”‚
           â”‚  - Select Top 5 models                       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ 5. Create Run Folder            â”‚
                â”‚ models/run_YYYYMMDD_HHMMSS/     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ 6. For Each Top Model:                           â”‚
         â”‚   - Save raw model (.pkl)                        â”‚
         â”‚   - Save metrics                                 â”‚
         â”‚   - Save full predictions                        â”‚
         â”‚   - Save plots (residuals, error, learning...)   â”‚
         â”‚   - Save configuration JSON                      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ 7. Finalize Best Model                 â”‚
                â”‚  - Saved separately inside run folder  â”‚
                â”‚    as best_model_<name>.pkl            â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Objectives

This script does:

- Loads prepared dataset from 1_datasets/
- Drops leakage columns
- Converts order_date to datetime
- Trains & evaluates models via PyCaret
- Compares and ranks models
- Saves top 5 model artifacts
- Saves the best model in the root of the run folder
- Saves:

  - Metrics
  - Predictions
  - Plots
  - Model config
  - Model object (.pkl)

## ğŸ“‚ Output Structure (Per Run)

Every execution creates a completely isolated folder:

```lua
4_data_analysis/
â””â”€â”€ models/
    â””â”€â”€ run_20251206_204501/
        â”œâ”€â”€ models_comparison.csv
        â”œâ”€â”€ best_model_gradient_boosting_regressor.pkl   â† ğŸ† Final best model
        â”œâ”€â”€ model_gradient_boosting_regressor/
        â”‚     â”œâ”€â”€ model.pkl
        â”‚     â”œâ”€â”€ config.json
        â”‚     â”œâ”€â”€ metrics.csv
        â”‚     â”œâ”€â”€ predictions.csv
        â”‚     â”œâ”€â”€ residuals.png
        â”‚     â”œâ”€â”€ error.png
        â”‚     â”œâ”€â”€ learning.png
        â”‚     â””â”€â”€ feature.png
        â”œâ”€â”€ model_random_forest_regressor/
        â”œâ”€â”€ model_catboost_regressor/
        â”œâ”€â”€ model_extra_trees_regressor/
        â””â”€â”€ model_lightgbm_regressor/
```

## ğŸ§¹ Preprocessing Rules

### Kept Columns

- All usable features not derived from future information

- order_date only

#### Dropped Columns (Leakage)

| Type   | Columns                               |
| --------- | ----------------------------|
| Date columns not known at prediction time | `receiving_ckd_date`, `finishing_date`,`shipping_date`|
| Derived lead times| `lead_time_to_finish`, `lead_time_to_ship`, `lead_time_from_ckd`|

### ğŸ¤– PyCaret Configuration

The script internally sets:

| Setting             | Value                            |
| ------------------- | -------------------------------- |
| Train/test split    | 80 / 20                          |
| Cross-validation    | 5-fold                           |
| Session seed        | 42                               |
| date_features       | `["order_date"]`                 |
| Engineered features | Day, month, year, week, etc.     |
| Encoding            | Automatic                        |
| Imputation          | Automatic                        |
| Feature scaling     | Automatic (if model requires it) |

### ğŸ§ª Model Evaluation

For each model, we save:

| Metric | Description                  |
| ------ | ---------------------------- |
| MAE    | Mean Absolute Error          |
| MSE    | Mean Squared Error           |
| RMSE   | Root Mean Squared Error      |
| RÂ²     | Coefficient of determination |
| MAPE   | Percentage error             |
| RMSLE  | Log loss error               |

Additionally, PyCaret generates:

- Residuals plot

- Error plot

- Feature importance

- Learning curve

### ğŸ’¾ Saved Artifacts

For EVERY model (top 5):

```lua
model.pkl
config.json
metrics.csv
predictions.csv
residuals.png
error.png
learning.png
feature.png
```

For BEST model ONLY:

```php-template
best_model_<name>.pkl
```

Stored directly in the run directory.

### â–¶ï¸ Running the Script

From the project root:

```bash
python 4_data_analysis/model_lead_time_pycaret.py
```

Artifacts will appear inside:

```bash
4_data_analysis/models/run_YYYYMMDD_HHMMSS/
```

### ğŸ” Reproducibility

This script guarantees:

- No dataset modification
- Each run stored independently
- Fixed random seed
- Full config saved as JSON
- All metrics saved

Anyone can re-run the script and reproduce the results exactly.
